{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LinearRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzS8TF3fe3GCgjknce3ogp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Odana5mY4yV1","colab_type":"code","colab":{}},"source":["!pip install -q sklearn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGUt7XV941gp","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from six.moves import urllib\n","\n","import tensorflow.compat.v2.feature_column as fc\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1k35MM4wyU64","colab_type":"code","colab":{}},"source":["dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n","dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"znKYXx_oynMV","colab_type":"code","colab":{}},"source":["dfeval.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMEXgcr8yu19","colab_type":"code","colab":{}},"source":["y_train = dftrain.pop('survived') # It removes the Survived column from the dataframe and we can consider them as a output variable.\n","y_eval = dfeval.pop('survived') # Similar, we are removing the column from the dataframe.\n","\n","dftrain.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzWW0mowzxz1","colab_type":"code","colab":{}},"source":["dftrain.describe() # It gives a more details analysis of the dataframe(of all the numerical columns)."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iM4HUwZ2MeF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"82a99db0-3dc1-4ca6-8de2-46a7d638e90e","executionInfo":{"status":"ok","timestamp":1589269600105,"user_tz":-60,"elapsed":430,"user":{"displayName":"Ashwin Pillai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6C1Xv4IDaqxZkdHt7Xb6fPWd9WLJiIGhQkO88=s64","userId":"02754679638289183735"}}},"source":["dftrain.shape # Provides the number of rows X number of columns"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(627, 9)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"NuZuVQwD2ZVz","colab_type":"code","colab":{}},"source":["dftrain.age.hist(bins=20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grx0Qd672vmB","colab_type":"code","colab":{}},"source":["print(dftrain.sex.value_counts())\n","dftrain.sex.value_counts().plot(kind = 'barh')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzJANoIW23cC","colab_type":"code","colab":{}},"source":["print(dftrain['class'].value_counts())\n","dftrain['class'].value_counts().plot(kind = 'barh')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ByUTRuM_3X84","colab_type":"code","colab":{}},"source":["print(pd.concat([dftrain,y_train], axis = 1).groupby('sex').survived.mean()) # It gives the percentage of survival based on their sex\n","pd.concat([dftrain,y_train], axis = 1).groupby('sex').survived.mean().plot(kind = 'barh').set_xlabel('% of survival')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5QLE2ALg7E5v","colab_type":"text"},"source":["We are using the above plot to understand our dataset. \n","Summary:\n","Majority of the passengers are in their mid 20's\n","There are more male passengers compared to the demale passengers\n","Majority are from third class\n","and Females have high survival rate when compared to men.\n"]},{"cell_type":"code","metadata":{"id":"ycyw_2Ba6IUd","colab_type":"code","colab":{}},"source":["dfeval.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-bpIOC57kyO","colab_type":"code","colab":{}},"source":["# Categorical columns - They are the non-numeric columns (Or columns with some kinnd of category) to which we will be assigning some integer values.\n","# Numeric columns - Nothing but integer columns."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPcAapp98lwQ","colab_type":"code","colab":{}},"source":["dftrain.columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk96A2to86Z9","colab_type":"code","colab":{}},"source":["CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch','class', 'deck', 'embark_town', 'alone']\n","NUMERIC_COLUMNS = ['age','fare']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tb__2sHV9Ksn","colab_type":"code","colab":{}},"source":["# We are using the feature_column module from the TensorFlow to assign a set of values to all the unique records in each of the above columns\n","feature_columns = []\n","\n","# For CATEGORICAL columns\n","\n","for feature_name in CATEGORICAL_COLUMNS:\n","  vocabulary = dftrain[feature_name].unique() # It provides the list of unique values in each of the columns and store them in vocabulary\n","  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n","\n","# For Numerical columns\n","\n","for feature_name in NUMERIC_COLUMNS:\n","  feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype = tf.float32))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TtQXTLKE-Kh2","colab_type":"code","colab":{}},"source":["print(feature_columns)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzdJU_7M_17G","colab_type":"code","colab":{}},"source":["# Preparing our input data for the model\n","\n","def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32): # here epochs - the no of times the data has to be shown to the model, for its understanding. Here the data is provided in the form of batch(batch_size defines the no of records in each batch)\n","  def input_function():  # inner function, this will be returned\n","    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n","    if shuffle:\n","      ds = ds.shuffle(1000)  # randomize order of data\n","    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n","    return ds  # return a batch of the dataset\n","  return input_function  # return a function object for use\n","\n","train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n","eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"unwOaOGyCRgh","colab_type":"code","colab":{}},"source":["linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n","linear_est.train(train_input_fn) # For the training purpose\n","result = linear_est.evaluate(eval_input_fn)\n","clear_output()\n","print(result['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-ozFmL1Dtxo","colab_type":"code","colab":{}},"source":["print(result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDbuF9-JEAr2","colab_type":"code","colab":{}},"source":["# We are predicting the values for the test dataset\n","\n","result = list(linear_est.predict(eval_input_fn))\n","print(result)\n","\n","# To find the probability of survival for the first record\n","print(dfeval.loc[0])\n","print(y_eval.loc[0])\n","print(result[0]['probabilities'][1])\n","\n","\n","# As per the result - The person has 3% chances of survival."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"90vY8t8aE6EQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}