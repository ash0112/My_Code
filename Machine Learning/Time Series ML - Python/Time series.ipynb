{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics and Algorithms CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required librabries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "series = read_csv('../Learning/data/Assignment Sample.csv', header=0, index_col=0)\n",
    "df = pd.read_csv(\"../Learning/data/Assignment Sample.csv\",parse_dates = [1], squeeze = True)\n",
    "data1 = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing two new columns of summarized data from monsoon and non-monsson months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['NONS'] = data1[['JAN','FEB','MAR','APR','MAY','NOV','DEC']].sum(axis=1)\n",
    "data1['MONS'] = data1[['JUN','JUL','AUG','SEP','OCT']].sum(axis=1)\n",
    "df['NONS'] = df[['JAN','FEB','MAR','APR','MAY','NOV','DEC']].sum(axis=1)\n",
    "df['MONS'] = df[['JUN','JUL','AUG','SEP','OCT']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the list of the different unique regions that are present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region = set(list(data1.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA (Integrated Autoregressive Moving Average) is a time series technique used for forecasting. In the forecasting equation, lags of the stationary series are called \"autoregressive\" terms, lags of the forecast errors are called \"moving average\" terms, and a time series that needs to be separated to be stationary is said to be an \"integrated\" variant of a stationary series.\n",
    "\n",
    "### An ARIMA model has main three inputs:\n",
    "###   • p is the number of autoregressive terms (by inspecting the Partial Autocorrelation (PACF) plot),\n",
    "###   • d is the number of nonseasonal differences needed for stationarity, and\n",
    "###   • q is the number of lagged forecast errors in the prediction equation (by inspecting the Partial Autocorrelation (PACF) plot).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[df[\"SUBDIVISION\"] == \"Kerala\"]\n",
    "\n",
    "df_sample1 = df_sample[[\"YEAR\",\"NONS\"]]\n",
    "df_sample1 = df_sample1.set_index(\"YEAR\")\n",
    "\n",
    "# Getting the moving mean\n",
    "\n",
    "sample1_mean = df_sample1.rolling(window = 20).mean()\n",
    "\n",
    "df_sample1.plot() \n",
    "sample1_mean.plot()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "values = pd.DataFrame(df_sample1.values)\n",
    "\n",
    "data_df = pd.concat([values,values.shift(1)], axis = 1)\n",
    "\n",
    "data_df.columns = [\"Actual\",\"Forecast\"]\n",
    "\n",
    "data_df = data_df[1:]\n",
    "\n",
    "# Calculating the mean square value\n",
    "\n",
    "data_error = mean_squared_error(data_df.Actual,data_df.Forecast)\n",
    "\n",
    "np.sqrt(data_error)\n",
    "\n",
    "# Plotting the ACF and PACF plots\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "plot_acf(df_sample1)\n",
    "\n",
    "plot_pacf(df_sample1)\n",
    "\n",
    "# Implementing the ARIMA model\n",
    "\n",
    "from  statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# Preparing the train and test data\n",
    "\n",
    "data_train = df_sample1[0:100]\n",
    "data_test = df_sample1[100:117]\n",
    "\n",
    "# Giving the p, d and q parameters for the ARIMA model\n",
    "\n",
    "data_model = ARIMA(data_train, order = (2,1,2))\n",
    "\n",
    "data_model_fit = data_model.fit()\n",
    "\n",
    "\n",
    "data_forecast = data_model_fit.forecast(steps = 17)[0]\n",
    "data_forecast_df = pd.DataFrame(data_forecast)\n",
    "data_forecast_df[\"YEAR\"] = [\"2001-01-01\",\"2002-01-01\",\"2003-01-01\",\"2004-01-01\",\"2005-01-01\",\n",
    "                \"2006-01-01\",\"2007-01-01\",\"2008-01-01\",\"2009-01-01\",\"2010-01-01\",\n",
    "                \"2011-01-01\",\"2012-01-01\",\"2013-01-01\",\"2014-01-01\",\"2015-01-01\",\n",
    "                \"2016-01-01\",\"2017-01-01\"]\n",
    "data_forecast_df.columns = [\"NONS\",\"YEAR\"]\n",
    "\n",
    "data_forecast_df = data_forecast_df[[\"YEAR\",\"NONS\"]]\n",
    "\n",
    "# Printing the forecast values \n",
    "\n",
    "print(data_forecast_df)\n",
    "\n",
    "# Printing the values from the test samples\n",
    "\n",
    "print(data_test)\n",
    "\n",
    "data_test_df = pd.DataFrame(data_test)\n",
    "error = mean_squared_error(data_test,data_forecast)\n",
    "\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the above dataset, ARIMA is not an ideal forecasting model. The dataset has 36 regions, which have to be individually passed into the model for forecasting as they are having a unique set of (p, d, q) values that needs to be manually inserted by observing the PACF (Partial Autocorrelation) and ACF (Autocorrelation) plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the original dataset when they are divided into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_values = df_sample1.values\n",
    "train, test = sample_values[:len(sample_values)-17], sample_values[len(sample_values)-17:]\n",
    "\n",
    "pyplot.plot(train)\n",
    "pyplot.plot([None for i in train] + [x for x in test])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An autoregressive (AR) model predicts future behavior based on past behavior. It’s used for forecasting when there is some correlation between values in a time series and the values that precede and succeed them. \n",
    "\n",
    "### In an AR model, the value of the outcome variable (Y) at some point t in time is directly related to the predictor variable (X) and previous values for Y. This is the main difference between simple linear regression and AR models.\n",
    "\n",
    "### The statsmodels library provides an autoregression model that automatically selects an appropriate lag value using statistical tests and trains a model. It is provided in the AR class. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(r, sample1):\n",
    "    X = sample1.values\n",
    "    \n",
    "    # Preparing the train and test data\n",
    "    \n",
    "    train, test = X[1:len(X)-17], X[len(X)-17:]\n",
    "    \n",
    "    # train autoregression\n",
    "    \n",
    "    model = AR(train)\n",
    "    model_fit = model.fit()\n",
    "    window = model_fit.k_ar\n",
    "    coef = model_fit.params\n",
    "    mean = sample1.mean(axis = 0)\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    \n",
    "    history = train[len(train)-window:]\n",
    "    history = [history[i] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        yhat = coef[0]\n",
    "        for d in range(window):\n",
    "            yhat += coef[d+1] * lag[window-d-1]\n",
    "        obs = test[t]\n",
    "        predictions.append(yhat)\n",
    "        history.append(obs)\n",
    "        \n",
    "        # Printing the predicted and the original values\n",
    "        \n",
    "        print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    print('Test MSE: %.3f' % error)\n",
    "    print(window)\n",
    "    \n",
    "    # plot\n",
    "    \n",
    "    pyplot.plot(test)\n",
    "    pyplot.plot(predictions, color='red')\n",
    "    pyplot.show()\n",
    "    rms = r2_score(test,predictions)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a 'for' loop so that the above function for all the Regions in the dataset\n",
    "\n",
    "for r in Region:\n",
    "    a = data1.loc[r]\n",
    "    b = df[df[\"SUBDIVISION\"] == r]\n",
    "    sample = pd.DataFrame(a)\n",
    "    sample = sample[[\"YEAR\",\"NONS\"]]\n",
    "    sample1 = sample.set_index('YEAR')\n",
    "    print(r)\n",
    "    \n",
    "    # Calling the above function\n",
    "    \n",
    "    prediction(r, sample1)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the AR model is univariant, we summarized all the non-monsoon months for the predictor variable (X). This helps in predicting only the summarized value but not the individual month data. Also, this model performs quite well for some of the regions (as they are having stationary data) but does not fit for a few of the regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Autoregression (VAR) is a multivariate forecasting algorithm that is used when two or more time-series influence each other. It is considered as an Autoregressive model because, each variable (Time Series) is modeled as a function of the past values, that is the predictors are nothing but the lags (time-delayed value) of the series.\n",
    "\n",
    "### The primary difference is that the above models (both ARIMA and AR) are unidirectional, where, the predictors influence the Y and not vice-versa. Whereas, Vector Auto Regression (VAR) is bi-directional. Each variable in this model is modeled as a linear combination of past values of itself and the past values of other variables in the system. Thus, the variables influence each other.\n",
    "\n",
    "### It can also be used for analysis of non-stationary multivariate time series \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "import matplotlib.pylab as plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a VAR model to train with the dataset\n",
    "\n",
    "def var_model1(r1, train1, test1):\n",
    "    yhat1 = [[]]\n",
    "    model = VAR(sample21)\n",
    "    test = test1\n",
    "    Region = r1\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(model_fit.y, steps=17)\n",
    "    df1 = pd.DataFrame(yhat)\n",
    "    df1.columns = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]\n",
    "    df1[\"YEAR\"] = range(2001,2018)\n",
    "    df1 = df1.set_index(\"YEAR\")\n",
    "    plot1 = df1[\"NOV\"].values\n",
    "    plot2 = test[\"NOV\"].values\n",
    "    \n",
    "    # Displaying the predicted values from the VAR model\n",
    "    \n",
    "    print(df1)\n",
    "    \n",
    "    # Plotting the predicted values against the original test values\n",
    "    \n",
    "    pyplot.plot(plot1, color = 'red')\n",
    "    pyplot.plot(plot2)\n",
    "    pyplot.show()\n",
    "     \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a 'for' loop so that the above function for all the Regions in the dataset\n",
    "\n",
    "for r1 in Region:\n",
    "    a1 = data1.loc[r1]\n",
    "    b1 = df[df[\"SUBDIVISION\"] == r1]\n",
    "    sample1 = pd.DataFrame(a1)\n",
    "    sample1 = sample1[[\"YEAR\",\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]]\n",
    "    sample21 = sample1.set_index('YEAR')\n",
    "    \n",
    "    # Preparing the train and test datasets\n",
    "    \n",
    "    train1, test1 = sample21[1:len(sample21)-17], sample21[len(sample21)-17:]\n",
    "    print(\"*\"*200)\n",
    "    print(r1)\n",
    "    \n",
    "    # Calling the above prepared VAR model function and passing the necessary parameters\n",
    "    \n",
    "    var_model1(r1, train1, test1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the VAR model to predict the next 5 years of rainfall for the NonMonsoon months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared a function to predict the future values using the same VAR model\n",
    "\n",
    "def var_model(r, sample2):\n",
    "    yhat1 = [[]]\n",
    "    \n",
    "    # Applying the in-built VAR model to the dataset\n",
    "    \n",
    "    model = VAR(sample2)\n",
    "    Region = r\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast(model_fit.y, steps=6)\n",
    "    \n",
    "    # Converting the above predicted values into a DataFrame\n",
    "    \n",
    "    df1 = pd.DataFrame(yhat)\n",
    "    df1.columns = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]\n",
    "    df1[\"YEAR\"] = range(2018,2024)\n",
    "    \n",
    "    # Plotting the above converted DataFrame \n",
    "    \n",
    "    df_Plot = df1.plot(x = \"YEAR\", y = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"], kind = \"barh\", figsize=(30, 15), fontsize = 25)\n",
    "    df_Plot.set_xlabel('Amount of Rainfall ', fontsize = 25)\n",
    "    df_Plot.set_ylabel('Year', fontsize = 25)\n",
    "    df_Plot.set_title(Region, fontsize = 25)\n",
    "    df1 = df1.set_index('YEAR')\n",
    "    \n",
    "    # Printing the predicted values\n",
    "    \n",
    "    print(df1)\n",
    "    return yhat\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a 'for' loop to call the above function for the future prediction for each Region\n",
    "\n",
    "for r in Region:\n",
    "    a = data1.loc[r]\n",
    "    b = df[df[\"SUBDIVISION\"] == r]\n",
    "    sample = pd.DataFrame(a)\n",
    "    sample = sample[[\"YEAR\",\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]]\n",
    "    sample2 = sample.set_index('YEAR')\n",
    "    print(\"*\"*220)\n",
    "    print(r)\n",
    "    \n",
    "    # Calling the above function and passing the necessary parameters\n",
    "    \n",
    "    var_model(r, sample2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the research problem is about predicting the rainfall for each of the non-monsoon months, thus making multiple input data. This model allows multiple inputs to be taken and lets us estimate future values for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"SUBDIVISION\"] == r].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a DataFrame for the last Region which was used for prediction in the above function\n",
    "\n",
    "a = pd.DataFrame(var_model(r, sample2))\n",
    "a.columns = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original data for the same Region\n",
    "\n",
    "testing = df[df[\"SUBDIVISION\"] == r]\n",
    "\n",
    "testing = testing[[\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"NOV\",\"DEC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the above prepared DataFrames\n",
    "\n",
    "new = pd.concat([testing, a], axis=0)\n",
    "\n",
    "new1 = new.reset_index()\n",
    "\n",
    "new1 = new1.iloc[:,1:]\n",
    "\n",
    "new1\n",
    "\n",
    "new1['NONS'] = new1[['JAN','FEB','MAR','APR','MAY','NOV','DEC']].sum(axis=1)\n",
    "\n",
    "new1 = new1[\"NONS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Train-Test Splits Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new1.values\n",
    "\n",
    "# Providing the split input (which is used to split the dataset)\n",
    "\n",
    "splits = TimeSeriesSplit(n_splits=2)\n",
    "pyplot.figure(1)\n",
    "index = 1\n",
    "for train_index, test_index in splits.split(X):\n",
    "    train = X[train_index]\n",
    "    test = X[test_index]\n",
    "    \n",
    "    # Printing the number of values in each train and test sets\n",
    "    \n",
    "    print('Observations: %d' % (len(train) + len(test)))\n",
    "    print('Training Observations: %d' % (len(train)))\n",
    "    print('Testing Observations: %d' % (len(test)))\n",
    "    \n",
    "    # Plotting the train and test datasets\n",
    "    \n",
    "    pyplot.subplot(310 + index)\n",
    "    pyplot.plot(train)\n",
    "    pyplot.plot([None for i in train] + [x for x in test])\n",
    "    index += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer to the Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question: Will the nonseasonal rainfall in India increase/decrease in the next 3 years?\n",
    "\n",
    "## Answer:\n",
    "\n",
    "### From a total of 36 different regions in India, 7 of the regions are expected to have high rainfall in May and November apart from the monsoon months (which extends from June to October every year).\n",
    "### While high rainfall is expected only in May in 9 regions and in December for 3 of the regions.\n",
    "### For the rest of the 17 regions, there is no high rainfall expected in the non-monsoon months for the next 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
